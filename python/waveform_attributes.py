#!/usr/bin/env python3

'''
Python script to creates attributes from the templates file generated by kilosort

Authors: Diego Canales, Brian Mullen
Date: 2025-01-22

Example:
    python waveform_attributes.py -i D:/Main/Data/File

'''

import os
import sys
import pandas as pd
import numpy as np

from scipy.signal import find_peaks


def normalize_templates(template_matrix, norm_factor=None):

    """
    Returns the normalized template matrix.  
    If norm_factor is None, it will calculate the norm_factor as the max value of each template

    Arguments:
        template_matrix: 3D array of the mean templates (n waveforms x n timepoints x n channels)
        norm_factor: 2D array to normalize against (n timepoints x n waveforms)

    Returns:
        templates_norm: 3D array of the normalized templates (n waveforms x n timepoints x n channels) 
        norm_factor: 2D array to normalize against (n timepoints x n waveforms)

    """
    templates_norm = np.swapaxes(template_matrix, 0, 2)
    try:
        norm_factor.shape
    except Exception as e:
        norm_factor = np.nanmax(np.abs(templates_norm), axis=(0,1))
    templates_norm = np.divide(templates_norm, norm_factor, out=np.zeros_like(templates_norm), 
                               where=norm_factor!=0)
    templates_norm = np.swapaxes(templates_norm, 0, 2)

    return templates_norm, norm_factor


def find_consecutive_ranges(values):
    """
    Returns the first and last value of each continuous set in a list of sorted values.
    
    Arguments:
        values: list of index values

    Returns:
        result: list of lists of start and end of each continous set of values
    """
    
    if not values:
        return []

    # Ensure the input list is sorted
    values = sorted(list(set(values))) # Using set() handles duplicates
    result = []
    first = last = values[0]
    for index in values[1:]:
        if index - last > 1:
            result.append([first, last])
            first = index
        last = index

    # Append the last range after the loop finishes
    result.append([first, last])
    
    return result


class waveform_features():

    '''
    class function to get all the waveform features from neuropixel data

    '''
    def __init__(self, template_matrix, template_vars_matrix=np.nan):
      '''
      initiate function with proper sequence of characterizations

      '''
      self.templates = template_matrix
      self.n_templates, self.n_time, self.n_channels = template_matrix.shape
      self.template_vars_matrix = template_vars_matrix
      if np.isnan(template_vars_matrix):
        self.variance = False
      else:
        self.variance = True

      self.get_biggest_waveform_channel()
      self.relevant_channels()
      self.get_waveform_stats()
      self.get_num_peaks()
      self.get_waveform_duration()

    def relevant_channels(self, n_max=10):

      '''
      Identify which channels of the multi-channel probe have activity related to the cluster

      Arguments:
          n_max: max number of channels that are saved in the list

      Returns:
          num_rel_channels: number of channels that have any activity
          channel_list: a sorted list of relevant channels
          most_active_ch: channel with the largest peak to peak amplitude
      '''

      channel_list = np.zeros((self.n_templates, n_max))
      num_rel_channels = np.zeros(self.n_templates)
      most_active_ch = np.zeros(self.n_templates)

      for n, template in enumerate(self.templates):
          #determines maximal magnitude of activation at each channel
          templates_max = np.max(template, axis=0)
          templates_min = np.min(template, axis=0)

          for t, tmax in enumerate(templates_max):
            if tmax < np.abs(templates_min[t]):
                templates_max[t] = np.abs(templates_min[t])

          #determines which channels have information (from templates)
          active_channels = np.where(np.ptp(template, axis=0)>0)[0]
          templates_max_active = templates_max[active_channels]
          order_desc = np.argsort(templates_max_active)[::-1]
          rel_channels = np.array(active_channels)
          channel_list[n,:] = rel_channels[order_desc][:n_max]

          #determines how many channels have relavent information
          ptp_per_channel = np.ptp(template, axis=0)

          num_rel_channels[n] = len(rel_channels)
          most_active_ch[n] = np.argmax(ptp_per_channel)

      self.channel_list = channel_list
      self.num_rel_channels = num_rel_channels
      self.most_active_ch = most_active_ch

    # Get Biggest Waveform Channel, waveforms, and magnitude
    def get_biggest_waveform_channel(self): 

      '''
      finds the channel location and value of the global maxima/minima of each waveform 
      stores the mean and variance waveforms of the biggest responses

      Returns:
        biggest_channel: channel index with the largest waveform
        biggest_value: amp of the largest waveform 
        stored_waveforms: waveforms of the channels with the biggest amp
        stored_varinance: waveforms of the channels with the biggest amp
      '''

      #max and min projections through time window, returns (n_waveforms x n_channels)
      templates_max = np.nanmax(self.templates, axis=1)
      templates_min = np.nanmin(self.templates, axis=1)

      #determine the  which channel has the global max and min, returns (n_waveforms)
      global_maxima_per_channel = np.nanargmax(templates_max, axis=1)
      global_minima_per_channel = np.nanargmin(templates_min, axis=1)

      #store which channel has the biggest waveform
      biggest_channel = global_maxima_per_channel.copy()
      biggest_value = np.zeros_like(biggest_channel)
      stored_waveforms = np.zeros(self.templates.shape[:-1])

      # stored_variances = np.zeros_like(stored_waveforms)*np.nan
      if self.variance:
          stored_variances = np.zeros_like(stored_waveforms)

      #iterate through the global_minima_per_channel
      for c, channel in enumerate(global_minima_per_channel):
          #check to see the magnitude of the minima is smaller than the magnitude of the maxima
          if np.abs(templates_min[c, channel]) < np.abs(templates_max[c, global_maxima_per_channel[c]]):
              #if so, update the biggest_channel_value with the new channel (based on the maxima)
              channel = global_maxima_per_channel[c]
              biggest_channel[c] = channel
              biggest_value[c] = templates_max[c, channel]
          else:
              biggest_value[c] = templates_min[c, channel]
          stored_waveforms[c] = templates_mean[c, :, channel]
          if self.variance:
              stored_variances[c] = templates_vars[c, :, channel]

      self.biggest_channel = biggest_channel
      self.biggest_value = biggest_value
      self.stored_waveforms = stored_waveforms
      if self.variance:
          self.stored_variances = stored_variances

    def get_waveform_stats(self):
      '''
      calculate cores statistics of waveform

      Returns:
        wave_stdev: waveform standard deviation
        wave_mean_10: waveform mean of the first 10 places only (used in waveform duration)
        wave_stdev_10: waveform stdev of the first 10 places only (used in waveform duration)
        wave_max: waveforms max amp
        wave_min: waveforms min amp
        wave_max_der: Max first derivative of waveform 
        wave_min_der: Min first derivative of waveform 
      '''

      self.wave_stdev = np.std(self.stored_waveforms, axis=1)
      self.wave_mean_10 = np.mean(self.stored_waveforms[:,:10], axis=1)
      self.wave_stdev_10 = np.std(self.stored_waveforms[:,:10], axis=1)
      self.wave_max = np.max(self.stored_waveforms, axis=1)
      self.wave_min = np.min(self.stored_waveforms, axis=1)
      self.wave_max_der = np.max(np.diff(self.stored_waveforms, axis=1), axis=0)
      self.wave_min_der = np.min(np.diff(self.stored_waveforms, axis=1), axis=0)

    def get_num_peaks(self,  
                      height:float = 0.1, 
                      distance:int = 1):

      '''
      Finds the number of peaks for all waveforms, returns the 3 largest magnitude peaks and time

      Arguments:
        height: the minimum peak height threshold for detection
        distance: intiger defining the minimum required samples between peaks

      Returns:
        n_peaks: number of peaks
        largest_peaks_locs: timepoints of the 3 largest peaks
        top_amps: the amplitude values of the 3 largest peaks
        top_amps_var: the variance values of the 3 largest peaks
      '''
      largest_peaks_locs = np.zeros((self.n_templates,3))*np.nan
      top_amps = np.zeros((self.n_templates,3))*np.nan
      top_amps_var = np.zeros((self.n_templates,3))*np.nan
      n_peaks = np.zeros(self.n_templates)

      for w, waveform in enumerate(self.stored_waveforms):

          peak_locs, peak_properties = find_peaks(np.abs(waveform), height=height, distance=distance) #detects peaks regardless of trajectory orientation
          n_peaks[w] = len(peak_locs)  #total num of peaks
          
          peak_amps = waveform[peak_locs]
          sorted_pas = np.argsort(np.abs(peak_amps))[::-1]  
          largest_locs = peak_locs[sorted_pas]

          if n_peaks[w] !=0:
            if largest_locs.shape[0] > 3:
              largest_peaks_locs[w,:] = largest_locs[:3]
              top_amps[w,:] = waveform[largest_locs[:3]]
              if self.variance:
                  top_amps_var[w,:] = self.stored_variances[w,largest_locs[:3]]
            else:
              largest_peaks_locs[w, :largest_locs.shape[0]] = largest_locs[:largest_locs.shape[0]]
              top_amps[w, :largest_locs.shape[0]] = waveform[largest_locs]
              if self.variance:
                  top_amps_var[w,:largest_locs.shape[0]] = self.stored_variances[w,largest_locs]

      self.n_peaks = n_peaks
      self.largest_peaks_locs = largest_peaks_locs
      self.top_amps = top_amps
      self.top_amps_var = top_amps_var

    def get_waveform_duration(self):

        '''
        Identify where each waveform starts based on the largest downward deflection
        when it reachers the after-hyperpolarization trough, and how long it takes to return to baseline

        Returns:
            AP_rise_time: time from the threshold crossing to main peak
            AP_fall_time: time from main peak to threshold crossing
            AHP_return_time: time from end of the AHP minimum back to baseline
            total_waveform_dur: start of rise to return to baseline 

        '''
        AP_rise_time = np.zeros((self.n_templates))*np.nan
        AP_fall_time = np.zeros((self.n_templates))*np.nan
        AHP_return_time =np.zeros((self.n_templates))*np.nan
        total_waveform_dur = np.zeros((self.n_templates))*np.nan

        for w, waveform in enumerate(self.stored_waveforms):
            
            baseline_upper_thresh = self.wave_mean_10[w] + (3.0 * self.wave_stdev_10[w])
            baseline_lower_thresh = self.wave_mean_10[w] - (3.0 * self.wave_stdev_10[w])
            
            upper = list(np.where((waveform>baseline_upper_thresh))[0])
            lower = list(np.where((waveform<baseline_lower_thresh))[0])
            
            cont_upper = find_consecutive_ranges(upper)
            cont_lower = find_consecutive_ranges(lower)
            
            min_index = np.argmin(waveform)
            
            for cont in cont_lower:
                if (min_index<=cont[1])&(min_index>=cont[0]):
                    start_idx = cont[0]
                    AHP_min_idx = cont[1]
                    break
                else:
                    start_idx = np.nan
                    AHP_min_idx =  np.nan

            for cont in cont_upper:
                if min_index<cont[0]:
                    return_idx = cont[1]
                    break
                else:
                    return_idx = np.nan

            AP_rise_time[w] = (min_index - start_idx)
            AP_fall_time[w] = (AHP_min_idx - min_index)
            AHP_return_time[w] = (return_idx - AHP_min_idx)
            total_waveform_dur[w] = (return_idx - start_idx)

        self.AP_rise_time = AP_rise_time 
        self.AP_fall_time = AP_fall_time 
        self.AHP_return_time = AHP_return_time 
        self.total_waveform_dur = total_waveform_dur


if __name__ == "__main__":

    import argparse
    import time
    import datetime

    # Argument Parsing
    # -----------------------------------------------
    ap = argparse.ArgumentParser()
    ap.add_argument('-i', '--input_directory', type = str,
        required = True, 
        help = 'directory path of kilosort files')
    args = vars(ap.parse_args())

    DATA_FOLDER = args['input_directory']
    assert os.path.exists(DATA_FOLDER), "Input data folder does not exist"

    print('Loading the following matrices:')
    templates_mean = np.load(os.path.join(DATA_FOLDER, 'templates.npy'))
    print(f'\ttemplates: {templates_mean.shape}') 
    
    try:
        templates_vars = np.load(os.path.join(DATA_FOLDER, 'templates_vars.npy'))
        print(f'\ttemplates_vars: {templates_vars.shape}')
        variance = True
    except:
        print('\t\tNo template variance found, skipping.  No variance attributes will be included.')
        variance = False
        templates_vars = np.nan

    try:
        cluster = pd.read_csv(os.path.join(DATA_FOLDER, 'cluster_info.tsv'), sep='\t')
    except:
        cluster = pd.read_csv(os.path.join(DATA_FOLDER, 'cluster_ContamPct.tsv'), sep='\t')

    #get normalized wavform, abs(max/min) value set to 1/-1
    templates_norm, norm_factor = normalize_templates(templates_mean, norm_factor=None)
    print(f'\ttemplates_norm: {templates_norm.shape}') 
    
    #use same normalizing factor on variance
    if variance:
      templates_vars_norm, norm_factor = normalize_templates(templates_vars, norm_factor=norm_factor)
      print(f'\ttemplates_vars_norm: {templates_vars_norm.shape}')
    else:
      templates_vars_norm = np.nan

    print('\nCharacterizing waveforms.')
    waveform_mean = waveform_features(templates_mean, templates_vars)
    waveform_norm = waveform_features(templates_norm, templates_vars_norm)

    # #Show Only Rel Waveforms Idx
    cluster['n_relevant_channel'] = waveform_norm.num_rel_channels
    cluster['most_active_channel'] = waveform_norm.most_active_ch
    cluster['largest_amp_channel'] = waveform_norm.biggest_channel
    cluster['largest_amp'] = waveform_norm.biggest_value

    # Peak information
    cluster['n_peaks'] = waveform_norm.n_peaks
    cluster['wave_start_amp'] = waveform_mean.stored_waveforms[:,0]
    cluster['wave_end_amp'] = waveform_mean.stored_waveforms[:,-1]

    for i in range(3):
        cluster['peak_time_{}'.format(i)] = waveform_mean.largest_peaks_locs[:,i]
        cluster['peak_amp_{}'.format(i)] = waveform_mean.top_amps[:,i]
        cluster['norm_peak_amp_{}'.format(i)] = waveform_norm.top_amps[:, i]
    
    cluster['ap_rise'] = waveform_norm.AP_rise_time
    cluster['ap_fall'] = waveform_norm.AP_fall_time
    cluster['ap_return'] = waveform_norm.AHP_return_time
    cluster['total_ap'] = waveform_norm.total_waveform_dur

    if variance:
        for i in range(3):
            cluster['peak_var_{}'.format(i)] = waveform_norm.top_amps_var[:,i]
            cluster['norm_peak_var_{}'.format(i)] = waveform_norm.top_amps_var[:, i]

    #DATA Export
    out_path = os.path.join(DATA_FOLDER, 'cluster_attribute_data.tsv')
    cluster.to_csv(out_path, sep = '\t', index=True)
    print(f'\tData saved to: {out_path}')







